{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets('MNIST_data',one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c8c1f50358>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c8bef26198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Image.fromarray((mnist.train.images[0]*255).reshape([28,28])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#从0开始到9\n",
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得批量样本\n",
    "batch_images,batch_labels = mnist.train.next_batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    #输入占位符\n",
    "    inputs = tf.placeholder(shape=[None,784],dtype=tf.float32)\n",
    "    #标记占位符\n",
    "    labels = tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
    "    \n",
    "    #输出层链接权重\n",
    "    out_weight = tf.Variable(tf.random_normal([784,10]))\n",
    "    #偏置值一般用0初始化\n",
    "    out_bias = tf.Variable(tf.zeros([10,]))\n",
    "    #可以使用正态分布、均匀分布初始化参数\n",
    "    #out_weight = tf.Variable(tf.random_normal_initializer([784,10]))\n",
    "    #out_bias = tf.Variable(tf.random_normal_initializer([10,]))\n",
    "    \n",
    "    #向前传播（函数）\n",
    "    logits = tf.matmul(inputs,out_weight) + out_bias\n",
    "    output = tf.nn.softmax(logits)\n",
    "    #可以使用不同的激活函数，例如sigmoid函数\n",
    "    #logits = 1 / (1+np.exp(inputs))\n",
    "    \n",
    "    \n",
    "    #代价函数\n",
    "    loss = tf.reduce_mean(- tf.reduce_sum(labels * tf.log(output + 1e-17),axis = 1))#第一个维度axis=1\n",
    "    \n",
    "    #正确率\n",
    "    acc = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(output,axis=1),tf.argmax(labels,axis=1)),tf.float32))\n",
    "    \n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train_op = optim.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 12.7632, acc 0.1518\n",
      "loss 6.7131, acc 0.3082\n",
      "loss 2.9222, acc 0.4517\n",
      "loss 3.2832, acc 0.5496\n",
      "loss 1.7570, acc 0.6124\n",
      "loss 1.7030, acc 0.6536\n",
      "loss 0.9344, acc 0.6860\n",
      "loss 1.6810, acc 0.7098\n",
      "loss 1.3540, acc 0.7285\n",
      "loss 1.1028, acc 0.7410\n",
      "loss 0.8551, acc 0.7525\n",
      "loss 2.5293, acc 0.7630\n",
      "loss 1.0066, acc 0.7690\n",
      "loss 0.9677, acc 0.7756\n",
      "loss 0.7058, acc 0.7812\n",
      "loss 0.9908, acc 0.7887\n",
      "loss 0.3766, acc 0.7926\n",
      "loss 0.6092, acc 0.7954\n",
      "loss 1.8419, acc 0.8001\n",
      "loss 1.4237, acc 0.8025\n",
      "loss 0.3764, acc 0.8092\n",
      "loss 0.8407, acc 0.8110\n",
      "loss 1.3331, acc 0.8142\n",
      "loss 1.1412, acc 0.8197\n",
      "loss 1.3282, acc 0.8206\n",
      "loss 0.9190, acc 0.8216\n",
      "loss 0.7747, acc 0.8251\n",
      "loss 1.4227, acc 0.8278\n",
      "loss 1.3290, acc 0.8278\n",
      "loss 1.0182, acc 0.8322\n",
      "loss 0.4429, acc 0.8354\n",
      "loss 1.2505, acc 0.8337\n",
      "loss 0.5433, acc 0.8365\n",
      "loss 0.4056, acc 0.8386\n",
      "loss 0.0309, acc 0.8427\n",
      "loss 0.0543, acc 0.8379\n",
      "loss 0.7711, acc 0.8423\n",
      "loss 1.7363, acc 0.8431\n",
      "loss 1.4843, acc 0.8446\n",
      "loss 0.4385, acc 0.8465\n",
      "loss 1.0221, acc 0.8446\n",
      "loss 0.1699, acc 0.8476\n",
      "loss 0.8396, acc 0.8488\n",
      "loss 0.6783, acc 0.8481\n",
      "loss 0.7406, acc 0.8509\n",
      "loss 0.9071, acc 0.8494\n",
      "loss 0.5472, acc 0.8518\n",
      "loss 0.2750, acc 0.8519\n",
      "loss 0.9969, acc 0.8545\n",
      "loss 0.1990, acc 0.8532\n",
      "loss 1.0708, acc 0.8536\n",
      "loss 0.5680, acc 0.8564\n",
      "loss 1.1536, acc 0.8551\n",
      "loss 0.3124, acc 0.8570\n",
      "loss 0.6527, acc 0.8524\n",
      "loss 0.5936, acc 0.8610\n",
      "loss 1.1839, acc 0.8608\n",
      "loss 0.8994, acc 0.8573\n",
      "loss 0.4776, acc 0.8608\n",
      "loss 1.2990, acc 0.8596\n",
      "loss 0.7135, acc 0.8610\n",
      "loss 1.0218, acc 0.8605\n",
      "loss 0.5859, acc 0.8626\n",
      "loss 0.7799, acc 0.8653\n",
      "loss 0.5311, acc 0.8616\n",
      "loss 0.4523, acc 0.8615\n",
      "loss 0.9379, acc 0.8656\n",
      "loss 0.6246, acc 0.8643\n",
      "loss 0.6040, acc 0.8642\n",
      "loss 0.7241, acc 0.8641\n",
      "loss 0.7001, acc 0.8681\n",
      "loss 0.4787, acc 0.8670\n",
      "loss 0.2258, acc 0.8649\n",
      "loss 1.6208, acc 0.8681\n",
      "loss 0.9008, acc 0.8696\n",
      "loss 0.2357, acc 0.8651\n",
      "loss 0.7001, acc 0.8681\n",
      "loss 0.3703, acc 0.8693\n",
      "loss 0.2749, acc 0.8713\n",
      "loss 1.0028, acc 0.8698\n",
      "loss 0.3781, acc 0.8694\n",
      "loss 0.8417, acc 0.8720\n",
      "loss 0.9823, acc 0.8688\n",
      "loss 0.3253, acc 0.8734\n",
      "loss 0.1946, acc 0.8692\n",
      "loss 0.8413, acc 0.8719\n",
      "loss 0.4705, acc 0.8736\n",
      "loss 0.3940, acc 0.8724\n",
      "loss 0.9383, acc 0.8728\n",
      "loss 0.5454, acc 0.8736\n",
      "loss 0.8736, acc 0.8716\n",
      "loss 1.0515, acc 0.8744\n",
      "loss 0.4085, acc 0.8740\n",
      "loss 0.5983, acc 0.8763\n",
      "loss 0.3894, acc 0.8704\n",
      "loss 0.0607, acc 0.8773\n",
      "loss 0.7283, acc 0.8731\n",
      "loss 0.2834, acc 0.8757\n",
      "loss 0.5213, acc 0.8728\n",
      "loss 0.2643, acc 0.8764\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    #可以更改学习率\n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "    #optim = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "    train_op = optim.minimize(loss)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range (50000):#更改成更大的数字提高正确率\n",
    "   #for i in range (80000):\n",
    "        batch_images,batch_labels = mnist.train.next_batch(32)\n",
    "        res_loss,_ = sess.run([loss,train_op],feed_dict={\n",
    "                                  inputs:batch_images,\n",
    "                                  labels:batch_labels\n",
    "                              })\n",
    "        if i % 500 == 0:\n",
    "            accs = []\n",
    "            #使用测试集衡量正确率\n",
    "            for j in range(10000 // 32):\n",
    "                batch_images,batch_labels = mnist.test.next_batch(32)\n",
    "                res_acc = sess.run(acc, feed_dict={\n",
    "                    inputs: batch_images,\n",
    "                    labels: batch_labels\n",
    "                })\n",
    "                accs.append(res_acc)\n",
    "            accs = np.mean(accs)\n",
    "            \n",
    "            #代价loss  正确率acc\n",
    "            print('loss %2.4f, acc %.4f' % (res_loss,accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如何改进模型以使得模型性能增强\n",
    "1、增大数据集，给模型提供更多的数据，剔除没有效用的数据\n",
    "2、人工分析误差\n",
    "3、分析模型的偏差和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如何给模型添加新的隐藏层并进行实验\n",
    "在输入层和输出层之间添加隐藏层，神经元结点的数目为128，并且每一层的每一个神经元结点都有自己的权重和偏置值。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
